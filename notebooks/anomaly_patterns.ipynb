{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Anomaly Patterns for Evaludation of AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from tsdr import tsdr\n",
    "from eval import groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meltria import loader\n",
    "\n",
    "metrics_files = !find /datasets/argowf-chaos-rq54b/ -type f -name \"*.json\" \n",
    "dataset_generator = loader.load_dataset_as_generator(metrics_files, target_metric_types={\n",
    "        \"containers\": True,\n",
    "        \"services\": True,\n",
    "        \"nodes\": True,\n",
    "        \"middlewares\": True,\n",
    "    },\n",
    "    num_datapoints=120,\n",
    ")\n",
    "\n",
    "rerords = [r for rec in dataset_generator for r in rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_by_case: dict[tuple[str, str], list[tuple[list[str], pd.DataFrame]]] = defaultdict(list)\n",
    "\n",
    "for record in rerords:\n",
    "    filtered_df: pd.DataFrame = tsdr.filter_out_no_change_metrics(record.data_df, parallel=True)\n",
    "    gt_candidates = groundtruth.select_ground_truth_metrics_in_routes(record.pk, filtered_df.columns.to_list(), record.chaos_type(), record.chaos_comp())\n",
    "    for routes, _ in gt_candidates:\n",
    "        route_by_case[record.chaos_type(), record.chaos_comp()].append((routes, filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"../samples/anomaly_patterns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import jsonlines\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_or_create_collection():\n",
    "    jsonl_files = glob.glob(f\"{SAVE_DIR}/*.jsonl\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_widget(yield_on_click) -> widgets.Box:\n",
    "    save_button = widgets.Button(description='Save')\n",
    "    skip_button = widgets.Button(description='Skip')\n",
    "    select_pattern = widgets.Select(\n",
    "        options=[\n",
    "            'Sudden increase', 'Sudden decrease', 'Level shift up', 'Level shift down', \n",
    "            'Steady increase', 'Steady decrease', 'Single spike', 'Single dip',\n",
    "            'Transient level shift up', 'Transient level shift down', 'Multiple spikes', 'Multiple dips', 'Fluctuations',\n",
    "            'White noise', 'Other normal',\n",
    "        ],\n",
    "        rows=15,\n",
    "        description='Pattern:',\n",
    "        layout=widgets.Layout(width='30%'),\n",
    "    )\n",
    "    select_position = widgets.Select(\n",
    "        options=[\"no anomaly\", \"anomaly_during_the_chaos\", \"anomaly_in_before_chaos\"],\n",
    "        layout=widgets.Layout(width='30%'),\n",
    "    )\n",
    "    output = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 4), clear=True)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    def show() -> None:\n",
    "        target_app, chaos_type, chaos_comp, metric, ts = next(yield_on_click)\n",
    "        ax.clear()\n",
    "        ax.set_title(f\"{chaos_type}/{chaos_comp}\\n{metric}\\n\")\n",
    "        ax.plot(ts)\n",
    "        with output:\n",
    "            display(ax.get_figure())\n",
    "\n",
    "    def on_save_click_callback(clicked_button: widgets.Button) -> None:\n",
    "        yield_on_click.send(select_position.value, select_pattern.value)\n",
    "        with output:\n",
    "            output.clear_output(wait=True)\n",
    "            print(f\"Selected {select_pattern.value} and {select_position.value}!\")\n",
    "        show()\n",
    "\n",
    "    save_button.on_click(on_save_click_callback)\n",
    "    plt.close(fig=fig)\n",
    "    show()\n",
    "\n",
    "    def on_skip_click_callback(clicked_button: widgets.Button) -> None:\n",
    "        with output:\n",
    "            output.clear_output(wait=True)\n",
    "            print(f\"Skipped\")\n",
    "        show()\n",
    "\n",
    "    skip_button.on_click(on_skip_click_callback)\n",
    "\n",
    "    return widgets.HBox([widgets.HBox([select_position, select_pattern]), widgets.VBox([save_button, skip_button]), output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_time_series(routes_by_case):\n",
    "    now = datetime.datetime.today().strftime('%Y%m%d-%H%M%S')\n",
    "    save_file_name = f\"{SAVE_DIR}/anomaly_patterns_{now}.jsonl\"\n",
    "    # append mode\n",
    "    writer = jsonlines.open(save_file_name, mode='a', flush=True)\n",
    "\n",
    "    for (chaos_type, chaos_comp), routes in routes_by_case.items():\n",
    "        unique_metric_check = {}\n",
    "        for metrics, filtered_df in routes:\n",
    "            for metric in metrics:\n",
    "                # skip duplicated metric\n",
    "                if metric in unique_metric_check and unique_metric_check[metric]:\n",
    "                    continue\n",
    "                unique_metric_check[metric] = True\n",
    "\n",
    "                ts = filtered_df.loc[:, metric].to_numpy()\n",
    "                position, pattern_name = (yield (record.target_app(), chaos_type, chaos_comp, metric, ts))\n",
    "                if position is None or pattern_name is None:\n",
    "                    continue\n",
    "                writer.write({\n",
    "                    'target_app': record.target_app(), \n",
    "                    'chaos_type': chaos_type,\n",
    "                    'chaos_comp': chaos_comp, \n",
    "                    'metric': metric,\n",
    "                    'anomaly_position': position,\n",
    "                    'anomaly_pattern': pattern_name,\n",
    "                    'time_series': ts.tolist(),\n",
    "                })\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = create_widget(gen_time_series(route_by_case))\n",
    "display(box)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0f02f5f97634d426ffcfa502db37ef392cddba0a927ded2fc10600c3b8bead5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
