{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FluxInfer RCA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from tsdr import tsdr\n",
    "from diagnoser import diag\n",
    "from eval import groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meltria import loader\n",
    "\n",
    "metrics_files = !find /datasets/argowf-chaos-rq54b/ -type f -name \"*.json\" | head -n 3\n",
    "dataset_generator = loader.load_dataset_as_generator(metrics_files, target_metric_types={\n",
    "        \"containers\": True,\n",
    "        \"services\": True,\n",
    "        \"nodes\": True,\n",
    "        \"middlewares\": True,\n",
    "    },\n",
    "    num_datapoints=120,\n",
    ")\n",
    "records = [r for rec in dataset_generator for r in rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_and_reduced_df: list = []\n",
    "for record in records:\n",
    "    # run tsdr\n",
    "    reducer = tsdr.Tsdr(\"residual_integral\", **{\n",
    "        \"step1_residual_integral_threshold\": 20,\n",
    "        \"step1_residual_integral_change_start_point\": False,\n",
    "        \"step1_residual_integral_change_start_point_n_sigma\": 3,\n",
    "        \"step2_clustering_method_name\": \"dbscan\",\n",
    "        \"step2_dbscan_min_pts\": 2,\n",
    "        \"step2_dbscan_dist_type\": 'sbd',\n",
    "        \"step2_dbscan_algorithm\": 'hdbscan',\n",
    "        \"step2_clustering_series_type\": 'raw',\n",
    "        \"step2_clustering_choice_method\": 'medoid',\n",
    "    })\n",
    "    tsdr_stat, clustering_info, anomaly_points = reducer.run(\n",
    "        X=record.data_df,\n",
    "        pk=record.pk,\n",
    "        max_workers=cpu_count(),\n",
    "    )\n",
    "    reduced_df = tsdr_stat[-1][0]\n",
    "    no_clustering_reduced_df = tsdr_stat[-2][0]\n",
    "    record_and_reduced_df.append((record, reduced_df, no_clustering_reduced_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import diagnoser.metric_node as mn\n",
    "\n",
    "def fisher_z(dm, cm, x, y) -> float:\n",
    "    m = dm.shape[0]\n",
    "    r = cm[x, y]\n",
    "    if 1 - r == 0. or 1 + r == 0.:\n",
    "        r = 1 - 1e-10\n",
    "    zstat = np.sqrt(m - 3) * 0.5 * np.log((1 + r) / (1 - r))\n",
    "    p_val = 2.0 * scipy.stats.norm.sf(np.absolute(zstat))\n",
    "    return p_val\n",
    "\n",
    "def build_wudg(pk, data_df: pd.DataFrame, init_graph_type=\"complete\") -> nx.Graph:\n",
    "    nodes = mn.MetricNodes.from_dataframe(data_df)\n",
    "    g: nx.Graph\n",
    "    match init_graph_type:\n",
    "        case \"complete\":\n",
    "            g = nx.Graph()\n",
    "            for (u, v) in combinations(nodes, 2):\n",
    "                g.add_edge(u, v)\n",
    "        case \"nw_call\":\n",
    "            g = diag.prepare_init_graph(nodes, pk)\n",
    "        case _:\n",
    "            assert False, f\"Unknown init_graph_type: {init_graph_type}\"\n",
    "\n",
    "    dm = data_df.to_numpy()\n",
    "    cm = np.corrcoef(dm.T)\n",
    "    _g = nx.relabel_nodes(g, mapping=nodes.node_to_num)\n",
    "    for (u, v) in _g.edges:\n",
    "        p_val = fisher_z(dm, cm, u, v)\n",
    "        _g[u][v]['weight'] = 1 / p_val if p_val != 0.0 else sys.float_info.max\n",
    "\n",
    "    return nx.relabel_nodes(_g, mapping=nodes.num_to_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record, reduced_df, no_clustering_reduced_df = record_and_reduced_df[1]\n",
    "WUDG = build_wudg(record.pk, reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_draw(graph: nx.Graph, ax):\n",
    "    pos=nx.spring_layout(graph, weight=None)\n",
    "    nx.draw_networkx(graph, pos=pos, ax=ax, font_size=8, node_size=150)\n",
    "    elabels = nx.get_edge_attributes(graph, 'weight')\n",
    "    for k, weight in elabels.items():\n",
    "        elabels[k] = f\"{weight:.2g}\"\n",
    "    nx.draw_networkx_edge_labels(graph, pos=pos, ax=ax, edge_labels=elabels, font_size=6)\n",
    "\n",
    "def draw_by_graph(graphs: list[nx.Graph], suptitle: str):\n",
    "    fig = plt.figure(1, figsize=(20, 20))\n",
    "    fig.suptitle(suptitle)\n",
    "    axs = fig.subplots(3, 2).flatten()\n",
    "\n",
    "    for ax, g in zip(axs, sorted(graphs, key=lambda g: len(g.nodes), reverse=True)[:5]):\n",
    "        pr = nx.pagerank(g, alpha=0.85) # default\n",
    "        display(sorted(pr.items(), reverse=True, key=lambda x: x[1])[:5])\n",
    "        nx_draw(g, ax)\n",
    "\n",
    "# for suptitle, graphs in ((\"Root contained graph\", root_contained_g), (\"Root uncontained graph\", root_uncontained_g)):\n",
    "#     draw_by_graph(graphs, suptitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank(WUDG, alpha=0.85) # default\n",
    "display(sorted(pr.items(), reverse=True, key=lambda x: x[1])[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate by AC@k and AVG@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr: dict[str, float] = nx.pagerank(WUDG, alpha=0.85) # default\n",
    "ranked_metric_to_score: list[tuple[mn.MetricNode, float]] = sorted(pr.items(), reverse=True, key=lambda x: x[1])\n",
    "ranked_metrics = mn.MetricNodes.from_list_of_metric_node([m for m, _ in ranked_metric_to_score])\n",
    "ok, cause_metrics = groundtruth.check_cause_metrics(\n",
    "    record.pk, ranked_metrics, chaos_type=record.chaos_type(), chaos_comp=record.chaos_comp(),\n",
    ")\n",
    "display(ok)\n",
    "for cm in cause_metrics:\n",
    "    display(f\"no:{list(ranked_metrics).index(cm)}\", cm)\n",
    "    plt.plot(reduced_df[str(cm)].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All fault cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meltria import loader\n",
    "\n",
    "metrics_files = !find /datasets/argowf-chaos-rq54b/ -type f -name \"*.json\"\n",
    "dataset_generator = loader.load_dataset_as_generator(metrics_files, target_metric_types={\n",
    "        \"containers\": True,\n",
    "        \"services\": True,\n",
    "        \"nodes\": True,\n",
    "        \"middlewares\": True,\n",
    "    },\n",
    "    num_datapoints=120,\n",
    ")\n",
    "records = [r for rec in dataset_generator for r in rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_and_reduced_df: list = []\n",
    "for record in records:\n",
    "    # run tsdr\n",
    "    reducer = tsdr.Tsdr(\"residual_integral\", **{\n",
    "        \"step1_residual_integral_threshold\": 20,\n",
    "        \"step1_residual_integral_change_start_point\": False,\n",
    "        \"step1_residual_integral_change_start_point_n_sigma\": 3,\n",
    "        \"step2_clustering_method_name\": \"dbscan\",\n",
    "        \"step2_dbscan_min_pts\": 2,\n",
    "        \"step2_dbscan_dist_type\": 'sbd',\n",
    "        \"step2_dbscan_algorithm\": 'hdbscan',\n",
    "        \"step2_clustering_series_type\": 'raw',\n",
    "        \"step2_clustering_choice_method\": 'medoid',\n",
    "    })\n",
    "    tsdr_stat, clustering_info, anomaly_points = reducer.run(\n",
    "        X=record.data_df,\n",
    "        pk=record.pk,\n",
    "        max_workers=cpu_count(),\n",
    "    )\n",
    "    reduced_df = tsdr_stat[-1][0]\n",
    "    no_clustering_reduced_df = tsdr_stat[-2][0]\n",
    "    record_and_reduced_df.append((record, reduced_df, no_clustering_reduced_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n",
      "/tmp/ipykernel_354894/717067231.py:31: RuntimeWarning: overflow encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# parallelize\n",
    "import joblib\n",
    "\n",
    "wudgs: list[tuple[nx.Graph, loader.DatasetRecord, pd.DataFrame, pd.DataFrame]]\n",
    "wudgs = joblib.Parallel(n_jobs=-1)(joblib.delayed(build_wudg)(record.pk, reduced_df) for record, reduced_df, no_clustering_reduced_df in record_and_reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/src/github.com/ai4sre/meltria-analyzer/.venv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:646: RuntimeWarning: overflow encountered in reduceat\n",
      "  value = ufunc.reduceat(data,\n",
      "/home/ubuntu/src/github.com/ai4sre/meltria-analyzer/.venv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:646: RuntimeWarning: overflow encountered in reduceat\n",
      "  value = ufunc.reduceat(data,\n",
      "/home/ubuntu/src/github.com/ai4sre/meltria-analyzer/.venv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:646: RuntimeWarning: overflow encountered in reduceat\n",
      "  value = ufunc.reduceat(data,\n",
      "/home/ubuntu/src/github.com/ai4sre/meltria-analyzer/.venv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:646: RuntimeWarning: overflow encountered in reduceat\n",
      "  value = ufunc.reduceat(data,\n",
      "/home/ubuntu/src/github.com/ai4sre/meltria-analyzer/.venv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:646: RuntimeWarning: overflow encountered in reduceat\n",
      "  value = ufunc.reduceat(data,\n",
      "/home/ubuntu/src/github.com/ai4sre/meltria-analyzer/.venv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:646: RuntimeWarning: overflow encountered in reduceat\n",
      "  value = ufunc.reduceat(data,\n",
      "/home/ubuntu/src/github.com/ai4sre/meltria-analyzer/.venv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:646: RuntimeWarning: overflow encountered in reduceat\n",
      "  value = ufunc.reduceat(data,\n",
      "/home/ubuntu/src/github.com/ai4sre/meltria-analyzer/.venv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:646: RuntimeWarning: overflow encountered in reduceat\n",
      "  value = ufunc.reduceat(data,\n",
      "/home/ubuntu/src/github.com/ai4sre/meltria-analyzer/.venv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:646: RuntimeWarning: overflow encountered in reduceat\n",
      "  value = ufunc.reduceat(data,\n",
      "/home/ubuntu/src/github.com/ai4sre/meltria-analyzer/.venv/lib/python3.10/site-packages/scipy/sparse/_compressed.py:646: RuntimeWarning: overflow encountered in reduceat\n",
      "  value = ufunc.reduceat(data,\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "prs: list[tuple[dict, loader.DatasetRecord, pd.DataFrame, pd.DataFrame]] = []\n",
    "prs = joblib.Parallel(n_jobs=-1)(joblib.delayed(nx.pagerank)(wudg, alpha=0.85) for wudg in wudgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import validation\n",
    "\n",
    "def check_validate_record(record) -> bool:\n",
    "    return validation.check_valid_dataset(\n",
    "        record, labbeling={\"n_sigma_rule\": {\"n_sigmas\": [2, 3]}}, fault_inject_time_index=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 77\n",
      "rank: 398, ts-preserve-service/pod-network-loss/0\n",
      "rank: 299, ts-train-mongo/pod-network-loss/0\n",
      "rank: 100, ts-price-service/pod-memory-hog/0\n",
      "rank: 27, ts-travel-service/pod-cpu-hog/0\n",
      "rank: 280, ts-auth-mongo/pod-memory-hog/0\n",
      "rank: 6, ts-train-service/pod-memory-hog/0\n",
      "rank: 2, ts-order-service/pod-cpu-hog/0\n",
      "rank: 20, ts-auth-mongo/pod-cpu-hog/0\n",
      "rank: 63, ts-basic-service/pod-cpu-hog/0\n",
      "rank: 291, ts-train-mongo/pod-memory-hog/0\n",
      "rank: 16, ts-preserve-service/pod-cpu-hog/0\n",
      "rank: 313, ts-food-mongo/pod-cpu-hog/0\n",
      "rank: 89, ts-price-mongo/pod-cpu-hog/0\n",
      "rank: 369, ts-order-service/pod-network-loss/0\n",
      "rank: 94, ts-station-service/pod-memory-hog/0\n",
      "rank: 410, ts-travel2-service/pod-network-loss/0\n",
      "rank: 370, ts-food-mongo/pod-network-loss/0\n",
      "rank: 6, ts-food-service/pod-memory-hog/0\n",
      "rank: 150, ts-travel2-service/pod-memory-hog/0\n",
      "rank: 36, ts-cancel-service/pod-memory-hog/0\n",
      "rank: 77, ts-payment-mongo/pod-cpu-hog/0\n",
      "rank: 17, ts-basic-service/pod-memory-hog/0\n",
      "rank: 367, ts-price-service/pod-network-loss/0\n",
      "rank: 377, ts-travel2-mongo/pod-network-loss/0\n",
      "rank: 332, ts-station-service/pod-cpu-hog/0\n",
      "rank: 395, ts-auth-service/pod-cpu-hog/0\n",
      "rank: 26, ts-consign-mongo/pod-memory-hog/0\n",
      "rank: 117, ts-station-mongo/pod-memory-hog/0\n",
      "rank: 352, ts-station-mongo/pod-network-loss/0\n",
      "rank: 278, ts-travel2-service/pod-cpu-hog/0\n",
      "rank: 252, ts-order-mongo/pod-network-loss/0\n",
      "rank: 18, ts-price-mongo/pod-memory-hog/0\n",
      "rank: 681, ts-user-mongo/pod-network-loss/0\n",
      "rank: 459, ts-consign-service/pod-cpu-hog/0\n",
      "rank: 57, ts-payment-service/pod-cpu-hog/0\n",
      "rank: 77, ts-train-mongo/pod-cpu-hog/0\n",
      "rank: 395, ts-travel-service/pod-network-loss/0\n",
      "rank: 259, ts-user-mongo/pod-cpu-hog/0\n",
      "no cause metrics: ts-food-mongo/pod-memory-hog/0\n",
      "rank: 9, ts-order-service/pod-memory-hog/0\n",
      "rank: 290, ts-station-mongo/pod-cpu-hog/0\n",
      "rank: 229, ts-travel-mongo/pod-cpu-hog/0\n",
      "rank: 197, ts-order-mongo/pod-cpu-hog/0\n",
      "rank: 861, ts-train-service/pod-network-loss/0\n",
      "rank: 397, ts-price-mongo/pod-network-loss/0\n",
      "rank: 46, ts-payment-mongo/pod-memory-hog/0\n",
      "rank: 263, ts-order-mongo/pod-memory-hog/0\n",
      "rank: 414, ts-order-other-service/pod-network-loss/0\n",
      "rank: 209, ts-price-service/pod-cpu-hog/0\n",
      "rank: 52, ts-preserve-service/pod-memory-hog/0\n",
      "rank: 367, ts-payment-service/pod-network-loss/0\n",
      "rank: 395, ts-consign-service/pod-network-loss/0\n",
      "no cause metrics: ts-cancel-service/pod-network-loss/0\n",
      "rank: 11, ts-travel-service/pod-memory-hog/0\n",
      "rank: 337, ts-consign-mongo/pod-network-loss/0\n",
      "rank: 8, ts-consign-service/pod-memory-hog/0\n",
      "no cause metrics: ts-food-service/pod-network-loss/0\n",
      "rank: 1, ts-train-service/pod-cpu-hog/0\n",
      "rank: 15, ts-user-service/pod-memory-hog/0\n",
      "rank: 358, ts-auth-service/pod-network-loss/0\n",
      "rank: 420, ts-basic-service/pod-network-loss/0\n",
      "rank: 8, ts-food-service/pod-cpu-hog/0\n",
      "rank: 185, ts-station-service/pod-network-loss/0\n",
      "rank: 186, ts-auth-service/pod-memory-hog/0\n",
      "rank: 94, ts-consign-mongo/pod-cpu-hog/0\n",
      "rank: 238, ts-travel2-mongo/pod-cpu-hog/0\n",
      "rank: 333, ts-auth-mongo/pod-network-loss/0\n",
      "rank: 147, ts-order-other-service/pod-cpu-hog/0\n",
      "rank: 80, ts-order-other-service/pod-memory-hog/0\n",
      "rank: 439, ts-travel-mongo/pod-network-loss/0\n",
      "rank: 352, ts-user-mongo/pod-memory-hog/0\n",
      "rank: 30, ts-payment-service/pod-memory-hog/0\n",
      "rank: 307, ts-travel2-mongo/pod-memory-hog/0\n",
      "rank: 254, ts-cancel-service/pod-cpu-hog/0\n",
      "rank: 208, ts-travel-mongo/pod-memory-hog/0\n",
      "no cause metrics: ts-payment-mongo/pod-network-loss/0\n",
      "rank: 325, ts-user-service/pod-network-loss/0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AC@K'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.012987012987012988,\n",
       " 2: 0.025974025974025976,\n",
       " 3: 0.025974025974025976,\n",
       " 4: 0.025974025974025976,\n",
       " 5: 0.025974025974025976,\n",
       " 6: 0.05194805194805195,\n",
       " 7: 0.05194805194805195,\n",
       " 8: 0.07792207792207792,\n",
       " 9: 0.09090909090909091,\n",
       " 10: 0.09090909090909091}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AVG@k'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.012987012987012988,\n",
       " 2: 0.01948051948051948,\n",
       " 3: 0.021645021645021644,\n",
       " 4: 0.022727272727272728,\n",
       " 5: 0.023376623376623377,\n",
       " 6: 0.02813852813852814,\n",
       " 7: 0.03153988868274583,\n",
       " 8: 0.037337662337662336,\n",
       " 9: 0.043290043290043295,\n",
       " 10: 0.048051948051948054}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "anomaly_case_sizes = len(prs)\n",
    "top_k_set = range(1, 11)\n",
    "ac_k: dict[int, float] = {k: 0.0 for k in top_k_set}\n",
    "rank_by_case: dict[str, list[int]] = defaultdict(list)\n",
    "print(len(prs), len(record_and_reduced_df))\n",
    "for pr, (record, reduced_df, non_clustering_reduced_df) in zip(prs, record_and_reduced_df):\n",
    "    ranked_metric_to_score: list[tuple[mn.MetricNode, float]] = sorted(pr.items(), reverse=True, key=lambda x: x[1])\n",
    "    ranked_metrics = mn.MetricNodes.from_list_of_metric_node([m for m, _ in ranked_metric_to_score])\n",
    "    _, cause_metrics = groundtruth.check_cause_metrics(\n",
    "        record.pk, ranked_metrics, chaos_type=record.chaos_type(), chaos_comp=record.chaos_comp(),\n",
    "    )\n",
    "    if len(cause_metrics) == 0:\n",
    "        print(f\"no cause metrics: {record.chaos_case_full()}\")\n",
    "        continue\n",
    "    rank: int = sorted([list(ranked_metrics).index(cm) for cm in cause_metrics])[0] + 1\n",
    "    print(f\"rank: {rank}, {record.chaos_case_full()}\")\n",
    "    rank_by_case[record.chaos_type()].append(rank)\n",
    "    # plt.plot(reduced_df[str(cm)].to_numpy())\n",
    "\n",
    "for k in top_k_set:\n",
    "    ac_k[k] = sum([1 if rank <= k else 0 for rank in chain.from_iterable(rank_by_case.values())]) / anomaly_case_sizes\n",
    "display(\"AC@K\", ac_k)\n",
    "\n",
    "avg_k = {}\n",
    "for k in top_k_set:\n",
    "    avg_k[k] = sum([ac_k[j] for j in range(1, k+1)]) / k\n",
    "display(\"AVG@k\", avg_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with service granulally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 77\n",
      "rank: 300, ts-preserve-service/pod-network-loss/0\n",
      "rank: 7, ts-train-mongo/pod-network-loss/0\n",
      "rank: 11, ts-price-service/pod-memory-hog/0\n",
      "rank: 9, ts-travel-service/pod-cpu-hog/0\n",
      "rank: 57, ts-auth-mongo/pod-memory-hog/0\n",
      "rank: 5, ts-train-service/pod-memory-hog/0\n",
      "rank: 1, ts-order-service/pod-cpu-hog/0\n",
      "rank: 20, ts-auth-mongo/pod-cpu-hog/0\n",
      "rank: 2, ts-basic-service/pod-cpu-hog/0\n",
      "rank: 4, ts-train-mongo/pod-memory-hog/0\n",
      "rank: 7, ts-preserve-service/pod-cpu-hog/0\n",
      "rank: 3, ts-food-mongo/pod-cpu-hog/0\n",
      "rank: 81, ts-price-mongo/pod-cpu-hog/0\n",
      "rank: 9, ts-order-service/pod-network-loss/0\n",
      "rank: 3, ts-station-service/pod-memory-hog/0\n",
      "rank: 61, ts-travel2-service/pod-network-loss/0\n",
      "rank: 6, ts-food-mongo/pod-network-loss/0\n",
      "rank: 1, ts-food-service/pod-memory-hog/0\n",
      "rank: 7, ts-travel2-service/pod-memory-hog/0\n",
      "rank: 36, ts-cancel-service/pod-memory-hog/0\n",
      "rank: 28, ts-payment-mongo/pod-cpu-hog/0\n",
      "rank: 4, ts-basic-service/pod-memory-hog/0\n",
      "rank: 9, ts-price-service/pod-network-loss/0\n",
      "rank: 115, ts-travel2-mongo/pod-network-loss/0\n",
      "rank: 9, ts-station-service/pod-cpu-hog/0\n",
      "rank: 6, ts-auth-service/pod-cpu-hog/0\n",
      "rank: 2, ts-consign-mongo/pod-memory-hog/0\n",
      "rank: 1, ts-station-mongo/pod-memory-hog/0\n",
      "rank: 237, ts-station-mongo/pod-network-loss/0\n",
      "rank: 29, ts-travel2-service/pod-cpu-hog/0\n",
      "rank: 7, ts-order-mongo/pod-network-loss/0\n",
      "rank: 18, ts-price-mongo/pod-memory-hog/0\n",
      "rank: 87, ts-user-mongo/pod-network-loss/0\n",
      "rank: 17, ts-consign-service/pod-cpu-hog/0\n",
      "rank: 5, ts-payment-service/pod-cpu-hog/0\n",
      "rank: 77, ts-train-mongo/pod-cpu-hog/0\n",
      "rank: 13, ts-travel-service/pod-network-loss/0\n",
      "rank: 25, ts-user-mongo/pod-cpu-hog/0\n",
      "rank: 5, ts-food-mongo/pod-memory-hog/0\n",
      "rank: 3, ts-order-service/pod-memory-hog/0\n",
      "rank: 21, ts-station-mongo/pod-cpu-hog/0\n",
      "rank: 19, ts-travel-mongo/pod-cpu-hog/0\n",
      "rank: 20, ts-order-mongo/pod-cpu-hog/0\n",
      "rank: 3, ts-train-service/pod-network-loss/0\n",
      "rank: 13, ts-price-mongo/pod-network-loss/0\n",
      "rank: 1, ts-payment-mongo/pod-memory-hog/0\n",
      "rank: 30, ts-order-mongo/pod-memory-hog/0\n",
      "rank: 5, ts-order-other-service/pod-network-loss/0\n",
      "rank: 28, ts-price-service/pod-cpu-hog/0\n",
      "rank: 28, ts-preserve-service/pod-memory-hog/0\n",
      "rank: 16, ts-payment-service/pod-network-loss/0\n",
      "rank: 7, ts-consign-service/pod-network-loss/0\n",
      "rank: 180, ts-cancel-service/pod-network-loss/0\n",
      "rank: 11, ts-travel-service/pod-memory-hog/0\n",
      "rank: 11, ts-consign-mongo/pod-network-loss/0\n",
      "rank: 8, ts-consign-service/pod-memory-hog/0\n",
      "rank: 1, ts-food-service/pod-network-loss/0\n",
      "rank: 1, ts-train-service/pod-cpu-hog/0\n",
      "rank: 14, ts-user-service/pod-memory-hog/0\n",
      "rank: 18, ts-auth-service/pod-network-loss/0\n",
      "rank: 95, ts-basic-service/pod-network-loss/0\n",
      "rank: 8, ts-food-service/pod-cpu-hog/0\n",
      "rank: 13, ts-station-service/pod-network-loss/0\n",
      "rank: 33, ts-auth-service/pod-memory-hog/0\n",
      "rank: 62, ts-consign-mongo/pod-cpu-hog/0\n",
      "rank: 3, ts-travel2-mongo/pod-cpu-hog/0\n",
      "rank: 5, ts-auth-mongo/pod-network-loss/0\n",
      "rank: 19, ts-order-other-service/pod-cpu-hog/0\n",
      "rank: 6, ts-order-other-service/pod-memory-hog/0\n",
      "rank: 16, ts-travel-mongo/pod-network-loss/0\n",
      "rank: 43, ts-user-mongo/pod-memory-hog/0\n",
      "rank: 11, ts-payment-service/pod-memory-hog/0\n",
      "rank: 8, ts-travel2-mongo/pod-memory-hog/0\n",
      "rank: 231, ts-cancel-service/pod-cpu-hog/0\n",
      "rank: 10, ts-travel-mongo/pod-memory-hog/0\n",
      "rank: 2, ts-payment-mongo/pod-network-loss/0\n",
      "rank: 9, ts-user-service/pod-network-loss/0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AC@K'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.07792207792207792,\n",
       " 2: 0.11688311688311688,\n",
       " 3: 0.18181818181818182,\n",
       " 4: 0.2077922077922078,\n",
       " 5: 0.2727272727272727,\n",
       " 6: 0.3116883116883117,\n",
       " 7: 0.37662337662337664,\n",
       " 8: 0.4155844155844156,\n",
       " 9: 0.4805194805194805,\n",
       " 10: 0.4935064935064935}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AVG@k'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.07792207792207792,\n",
       " 2: 0.09740259740259741,\n",
       " 3: 0.12554112554112554,\n",
       " 4: 0.14610389610389612,\n",
       " 5: 0.17142857142857143,\n",
       " 6: 0.19480519480519484,\n",
       " 7: 0.2207792207792208,\n",
       " 8: 0.24512987012987014,\n",
       " 9: 0.2712842712842713,\n",
       " 10: 0.2935064935064935}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'pod-network-loss:AC@K'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.038461538461538464,\n",
       " 2: 0.07692307692307693,\n",
       " 3: 0.11538461538461539,\n",
       " 4: 0.11538461538461539,\n",
       " 5: 0.19230769230769232,\n",
       " 6: 0.23076923076923078,\n",
       " 7: 0.34615384615384615,\n",
       " 8: 0.34615384615384615,\n",
       " 9: 0.46153846153846156,\n",
       " 10: 0.46153846153846156}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'pod-network-loss:AVG@K'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.038461538461538464,\n",
       " 2: 0.057692307692307696,\n",
       " 3: 0.07692307692307693,\n",
       " 4: 0.08653846153846154,\n",
       " 5: 0.10769230769230768,\n",
       " 6: 0.1282051282051282,\n",
       " 7: 0.15934065934065936,\n",
       " 8: 0.1826923076923077,\n",
       " 9: 0.2136752136752137,\n",
       " 10: 0.2384615384615385}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'pod-memory-hog:AC@K'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.11538461538461539,\n",
       " 2: 0.15384615384615385,\n",
       " 3: 0.23076923076923078,\n",
       " 4: 0.3076923076923077,\n",
       " 5: 0.38461538461538464,\n",
       " 6: 0.4230769230769231,\n",
       " 7: 0.46153846153846156,\n",
       " 8: 0.5384615384615384,\n",
       " 9: 0.5384615384615384,\n",
       " 10: 0.5769230769230769}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'pod-memory-hog:AVG@K'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.11538461538461539,\n",
       " 2: 0.13461538461538464,\n",
       " 3: 0.16666666666666666,\n",
       " 4: 0.20192307692307693,\n",
       " 5: 0.23846153846153845,\n",
       " 6: 0.2692307692307692,\n",
       " 7: 0.2967032967032967,\n",
       " 8: 0.3269230769230769,\n",
       " 9: 0.3504273504273504,\n",
       " 10: 0.3730769230769231}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'pod-cpu-hog:AC@K'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.08,\n",
       " 2: 0.12,\n",
       " 3: 0.2,\n",
       " 4: 0.2,\n",
       " 5: 0.24,\n",
       " 6: 0.28,\n",
       " 7: 0.32,\n",
       " 8: 0.36,\n",
       " 9: 0.44,\n",
       " 10: 0.44}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'pod-cpu-hog:AVG@K'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.08,\n",
       " 2: 0.1,\n",
       " 3: 0.13333333333333333,\n",
       " 4: 0.15000000000000002,\n",
       " 5: 0.168,\n",
       " 6: 0.18666666666666668,\n",
       " 7: 0.20571428571428574,\n",
       " 8: 0.22500000000000003,\n",
       " 9: 0.2488888888888889,\n",
       " 10: 0.268}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "anomaly_case_sizes = len(prs)\n",
    "top_k_set = range(1, 11)\n",
    "ac_k: dict[int, float] = {k: 0.0 for k in top_k_set}\n",
    "rank_by_case: dict[str, list[int]] = defaultdict(list)\n",
    "print(len(prs), len(record_and_reduced_df))\n",
    "for pr, (record, reduced_df, non_clustering_reduced_df) in zip(prs, record_and_reduced_df):\n",
    "    chaos_service: str = record.chaos_comp().removesuffix(\"-service\").removesuffix(\"-mongo\")\n",
    "    ranked_metric_to_score: list[tuple[mn.MetricNode, float]] = sorted(pr.items(), reverse=True, key=lambda x: x[1])\n",
    "    rank: int = sorted([i+1 for i, (m, _) in enumerate(ranked_metric_to_score) if m.comp.startswith(chaos_service)])[0]\n",
    "    print(f\"rank: {rank}, {record.chaos_case_full()}\")\n",
    "    rank_by_case[record.chaos_type()].append(rank)\n",
    "    # plt.plot(reduced_df[str(cm)].to_numpy())\n",
    "\n",
    "for k in top_k_set:\n",
    "    ranks = chain.from_iterable(rank_by_case.values())\n",
    "    ac_k[k] = sum([1 if rank <= k else 0 for rank in ranks]) / anomaly_case_sizes\n",
    "display(\"AC@K\", ac_k)\n",
    "\n",
    "avg_k = {}\n",
    "for k in top_k_set:\n",
    "    avg_k[k] = sum([ac_k[j] for j in range(1, k+1)]) / k\n",
    "display(\"AVG@k\", avg_k)\n",
    "\n",
    "for case, ranks in rank_by_case.items():\n",
    "    _ac_k, _avg_k = {}, {}\n",
    "    for k in top_k_set:\n",
    "        _ac_k[k] = sum([1 if rank <= k else 0 for rank in ranks]) / len(ranks)\n",
    "        _avg_k[k] = sum([_ac_k[j] for j in range(1, k+1)]) / k\n",
    "    display(f\"{case}:AC@K\", _ac_k)\n",
    "    display(f\"{case}:AVG@K\", _avg_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0f02f5f97634d426ffcfa502db37ef392cddba0a927ded2fc10600c3b8bead5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
